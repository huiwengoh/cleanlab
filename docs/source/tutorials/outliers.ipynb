{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5decad3c",
   "metadata": {},
   "source": [
    "# Detecting Outliers with Cleanlab and PyTorch Image Models (timm)\n",
    "\n",
    "This 5-minute tutorial shows how to detect outliers in image data using Cleanlab and PyTorch. We use the **cifar10** dataset where each image belongs to 1 of 10 classes: `[airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck]`. You can easily replace the image dataset + neural network used here with any other Pytorch dataset + neural network (e.g. to instead detect outliers in text data). \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Pre-process [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) to create a Pytorch dataset.\n",
    "- Create `train_data` and `test_data` such that `train_data` only contains images of animals and `test_data` contains images from all classes.\n",
    "- Load pretrained `timm` neural network model and extract `train_data` and `test_data` feature embeddings from its representations.\n",
    "- Use `cleanlab` to find naturally occurring outlier examples in the `train_data` (i.e. atypical images).\n",
    "- Find outlier examples in the `test_data` that do not stem from training data distribution (including out-of-distribution non-animal images).\n",
    "- Explore threshold selection for determining which images are outliers vs not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41552bff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "Already have numeric feature embeddings for your data? Just run the code below to compute outlier scores.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "    \n",
    "# To get outlier scores for train_data using feature matrix train_feature_embeddings\n",
    "outlier_scores, knn = get_outlier_scores(features=train_feature_embeddings, return_estimator=True)\n",
    "\n",
    "# To get outlier scores for additional test_data using feature matrix test_feature_embeddings\n",
    "test_outlier_scores = get_outlier_scores(features=test_feature_embeddings, knn=knn)\n",
    "    \n",
    "    \n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a3608",
   "metadata": {},
   "source": [
    "## 1. Install the required dependencies\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install matplotlib sklearn torch torchvision timm\n",
    "!pip install cleanlab\n",
    "...\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb3aed",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used: matplotlib==3.5.1, torch==1.11.0, torchvision==0.12.0, timm==0.5.4\n",
    "\n",
    "dependencies = [\"matplotlib\", \"torch\", \"torchvision\", \"sklearn\", \"timm\", \"cleanlab\"]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb76474",
   "metadata": {},
   "source": [
    "Let's first import the required packages and set some seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings\n",
    "\n",
    "import cleanlab\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.neighbors import NearestNeighbors # import KNN estimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timm # resnet50 pre-trained model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e482550",
   "metadata": {},
   "source": [
    "## 2. Pre-process the Cifar10 dataset\n",
    "\n",
    "After loading the data and processing the images, we manually remove some classes from the training dataset thereby making images from these classes outliers in the test set. For this example we've chosen to remove all classes that are not an animal, such that images from the following classes are considered out-of-distribution: `[airplane, automobile, ship, truck]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 images into tensors for training (rescales pixel values to [0,1] interval):\n",
    "transform_normalize = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_normalize)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_normalize)\n",
    "\n",
    "# Remove non-animal images from the training dataset\n",
    "animal_classes = [2,3,4,5,6,7]  # which labels correspond to images of animals\n",
    "animal_idxs = np.where(np.isin(train_data.targets, animal_classes))[0]\n",
    "\n",
    "# Only work with small subset of each dataset to speedup tutorial\n",
    "train_idxs = np.random.choice(animal_idxs, len(animal_idxs) // 6, replace=False)\n",
    "test_idxs = np.random.choice(range(len(test_data)), len(test_data) // 10, replace=False)\n",
    "\n",
    "train_data  = torch.utils.data.Subset(train_data, train_idxs)  # select subset of animal images for train_data\n",
    "test_data  = torch.utils.data.Subset(test_data, test_idxs)  # select subset of all images for test_data\n",
    "print('train_data length: %s' % (len(train_data)))\n",
    "print('test_data length: %s' % (len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee4891",
   "metadata": {},
   "source": [
    "#### Visualize some of the training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_classes = {0: 'airplane', \n",
    "              1: 'automobile', \n",
    "              2: 'bird',\n",
    "              3: 'cat', \n",
    "              4: 'deer', \n",
    "              5: 'dog', \n",
    "              6: 'frog', \n",
    "              7: 'horse', \n",
    "              8:'ship', \n",
    "              9:'truck'}\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "def plot_images(dataset):\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "    for i in range(15):\n",
    "        X,y = dataset[i]\n",
    "        ax = plt.subplot(3,5,i+1)\n",
    "        ax.set_title(txt_classes[int(y)])\n",
    "        ax.imshow(imshow(X))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29c605",
   "metadata": {},
   "source": [
    "Observe how there are only animals left in the training set `train_data` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37de093",
   "metadata": {},
   "source": [
    "The test set on the other hand still visibily contains the non-animal images from classes like `[ship, airplane, automobile, truck]`. If we consider `train_data` to be representative of the typical data distribution, then these non-animal images in `test_data` become outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cfb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691c515",
   "metadata": {},
   "source": [
    "## 3. Represent each image as feature embeddings\n",
    "\n",
    "We construct a neural network and pass images through the network to generate vector embeddings via its hidden layer representation. Here we import a `resnet50` network from [timm](https://timm.fast.ai/), where this model has been pretrained on a large corpus of other images. \n",
    "\n",
    "Note that cleanlab's outlier detection can be applied to feature embeddings generated from any model (or to the raw data features if they are already numeric vectors). Outlier detection works best with moderately-dimensional feature vectors, in which values along each dimension are of a similar scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e22a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 2048-dimensional feature embeddings from images\n",
    "def embed_images(model, dataloader):\n",
    "    feature_embeddings = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(images)\n",
    "            feature_embeddings.extend(embeddings.numpy())\n",
    "    feature_embeddings = np.array(feature_embeddings)\n",
    "    return feature_embeddings  # each row corresponds to embedding of a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93be3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download neural network from timm\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=0)  # this is a pytorch network\n",
    "model.eval()  # eval mode disables training-time operators (like batch normalization)\n",
    "\n",
    "# Create dataloaders efficiently streaming images through the network\n",
    "batch_size = 50\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Generate feature embeddings of the training data using the model\n",
    "train_feature_embeddings = embed_images(model, trainloader)\n",
    "print(f'Train embeddings pooled shape: {train_feature_embeddings.shape}')\n",
    "\n",
    "# Generate feature embeddings of the test data using the model\n",
    "test_feature_embeddings = embed_images(model, testloader)\n",
    "print(f'Test embeddings pooled shape: {test_feature_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f7725",
   "metadata": {},
   "source": [
    "## 4. Use cleanlab to find outliers in the dataset\n",
    "\n",
    "#### Scoring outliers in training data\n",
    "\n",
    "Calling cleanlab's ``get_outlier_score()`` on ``train_feature_embeddings`` will find any naturally occuring outliers in ``train_data``. These examples are atypical images that look strange or different from the majority of examples in the dataset. In our case, these correspond to odd-looking images of animals that do not resemble typical animals depicted in **cifar10**. This method produces a score in [0,1] for each example, where lower values correspond to more atypical examples (more likely out-of-distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef10ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outlier scores for each of our train_data feature embeddings\n",
    "train_outlier_scores, knn = get_outlier_scores(features=train_feature_embeddings, return_estimator=True)\n",
    "\n",
    "# View images with top 15 outlier scores\n",
    "top_train_outlier_idxs = train_outlier_scores.argsort()[:15]\n",
    "top_train_outlier_subset = torch.utils.data.Subset(train_data, top_train_outlier_idxs)\n",
    "plot_images(top_train_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e1639",
   "metadata": {},
   "source": [
    "For fun, let's see what `cleanlab` considers the least likely outliers in the training data! These examples look very homogeneous as each one is highly similar to many other training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 15 least likely outliers in train_data\n",
    "bottom_train_outlier_idxs = (-train_outlier_scores).argsort()[:15]\n",
    "bottom_train_outlier_subset = torch.utils.data.Subset(train_data, bottom_train_outlier_idxs)\n",
    "plot_images(bottom_train_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61020539",
   "metadata": {},
   "source": [
    "#### Scoring outliers in additional test data\n",
    "\n",
    "Now suppose we want to find outlier images in our additional test data, in particular images unlikely to stem from the same distribution as the training data. We can again use `get_outlier_scores()` this time passing in the previously-fitted estimator `knn` used to measure similarity between training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9cde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outlier_scores = get_outlier_scores(features=test_feature_embeddings, knn=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ab6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 15 most severe outliers in test data\n",
    "top_outlier_idxs = (test_outlier_scores).argsort()[:15]\n",
    "top_outlier_subset = torch.utils.data.Subset(test_data, top_outlier_idxs)\n",
    "plot_images(top_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f62378",
   "metadata": {},
   "source": [
    "Notice how almost all outliers identified in `test_data` belong to (non-animal) classes not present in the training data. These non-animal images have very different feature embeddings than the training images which are all animals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2df5a",
   "metadata": {},
   "source": [
    "#### Evaluating out of distribution detection performance \n",
    "\n",
    "Since we have access to ground-truth labels here (which is not necessary for outlier detection with cleanlab), \n",
    "we can evaluate our outlier scores for out-of-distribution detection, in which the goal is to find test images whose label does not correspond to any of the classes in the training data. We plot the precision/recall achieved by our outlier scores for the test data (which is a mix of animal and non-animal images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_labels = np.array(test_data.dataset.targets) # Get subset labels from out test_data\n",
    "animal_idxs = np.where(np.isin(test_data_labels[test_data.indices], animal_classes))[0] # Find animal idxs\n",
    "not_outlier = np.zeros(len(test_data), dtype=bool)\n",
    "not_outlier[animal_idxs] = True\n",
    "precision, recall, thresholds = precision_recall_curve(not_outlier, test_outlier_scores)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.title(\"Out-of-Distribution Detection Performance\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baae839",
   "metadata": {},
   "source": [
    "#### Deciding which test examples are outliers\n",
    "\n",
    "Given outlier scores, how do we determine how many of the top-ranked examples in ``test_data`` should be marked as outliers? \n",
    "\n",
    "Inevitably this has some true positive / false positive trade-off, so let's suppose we want to ensure around at most 5% false positives. We can use the 5-th percentile of the distribution of `train_outlier_scores` (assuming the training data are in-distribution examples without outliers) as a hard score threshold below which to consider a test example an outlier.\n",
    "\n",
    "Let's compute the 5th percentile of the training outlier score distribution (shown as red line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_percentile = np.percentile(train_outlier_scores, 5)  # 5th percentile of the train_data distribution\n",
    "\n",
    "# Plot outlier_score distributions and the 5th percentile cutoff\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "plt_range = [min(train_outlier_scores.min(),test_outlier_scores.min()), \\\n",
    "             max(train_outlier_scores.max(),test_outlier_scores.max())]\n",
    "axes[0].hist(train_outlier_scores, range=plt_range, bins=50)\n",
    "axes[0].set(title='train_outlier_scores distribution', ylabel='Frequency')\n",
    "axes[0].axvline(x=fifth_percentile, color='red', linewidth=2)\n",
    "axes[1].hist(test_outlier_scores, range=plt_range, bins=50)\n",
    "axes[1].set(title='test_outlier_scores distribution', ylabel='Frequency')\n",
    "axes[1].axvline(x=fifth_percentile, color='red', linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55362e5d",
   "metadata": {},
   "source": [
    "All test examples whose `test_outlier_scores` fall left of the red line will be marked as an outlier.\n",
    "\n",
    "Let's plot the least-certain outliers of our `test_data`. These are the images immediately to the left of that cutoff threshold (red line). The majority of them are still truly out-of-distribution non-animal images, but there are a few atypical-looking animals that are now erroneously identified as outliers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e40fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 15 images with outlier scores right along the cuttoff (i.e. those images we've identified as outliers that we're least sure about)\n",
    "sorted_idxs = test_outlier_scores.argsort()\n",
    "outlier_scores = test_outlier_scores[sorted_idxs]\n",
    "outlier_indices = sorted_idxs[outlier_scores < fifth_percentile]  # Images in test data flagged as outliers\n",
    "\n",
    "selected_outlier_subset = torch.utils.data.Subset(test_data, outlier_indices[::-1])\n",
    "plot_images(selected_outlier_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d376c1",
   "metadata": {},
   "source": [
    "#### How does cleanlab detect outliers?\n",
    "\n",
    "Outlier scores are defined relative to the average distance (computed over feature values) between each example and its K nearest neighbors in the training data. Such scores have been found to be particularly effective for out-of-distribution detection, see this paper for more details:\n",
    "\n",
    "[Back to the Basics: Revisiting Out-of-Distribution Detection Baselines](https://arxiv.org/abs/2207.03061)\n",
    "\n",
    "\n",
    "Internally, `cleanlab` uses the `sklearn.neighbors.NearestNeighbor` class (with *cosine* distance) to find the K nearest neighbors, but you can easily use another KNN estimator with `get_outlier_scores()`. Note that this class by default utilizes the *minkowski* distance, but we recommend using *cosine* distance between neural net representations of data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a8774",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "# Verify the top identified test outliers data are mostly non-animal images\n",
    "num_animals = len([i for i in range(len(top_outlier_subset)) if top_outlier_subset[i][1] in animal_classes])\n",
    "if 1 - (num_animals / len(top_outlier_subset)) < 0.81:\n",
    "    raise Exception(\"Not enough non-animal images amongst top-ranked outliers in test_data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
